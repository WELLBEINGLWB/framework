#include "visual_servo_control_node.h"

	              		                         /*
	              		                        ###
 	          		                      ## ##
	          		                      ##  ##
	          		                       ####
	          		                         :
 	          		                       #####
	          		                       ######
	          		                       ##  ##
	          		                       ##  ##
	          		                       ##  ##
	          		                       ##  ##########
 	          		                      ##  #############
	          		                  #######  ###############
	          		              #############################
	          		        .###################################
	          		       #####################################;
	          		       ##                                 ##.
	          		       ##                                 ##
	          		       #####################################
	          		       ##                                 ##
	          		       ##       The cake is a lie         ##
	          		       ##                                 ###
	          		    #####                                 #####
	          		   ### ##################################### ###
	          		  ###  ##                                 ##  ###
	          		  ##   ##                                 ##   ##
	          		  ##   ##,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,##   ##
	          		   ##  #####################################  ##
	          		    ##                                       ##
	          		     ####                                 ####
	          		       ######                         ######
          			          ##############################*/
          			          
          		
          		
          		
          		
 
 
bool getVelocityVector_Point(visual_servo_control::request_servo_velocity_vector::Request &req, visual_servo_control::request_servo_velocity_vector::Response &res)
{
	// This part of the function gets locked if it is still calculating the next velocity
	// vector in the servo application. Hence, this service will return false if it is still busy. 
	ROS_INFO("Service called (getVelocityVector_Point)");
	std::string request_message = req.request_message.c_str();
	if(!program_lock)
	{
	     ROS_INFO("Program not locked, starting getVelocityVector_Point");
		program_lock = true;
          try {
               // If the servo system is not yet initialized, then initialize global variables.
               // The control message is compared to the incoming request message.
               std::string control_message = "initialize";
               if(!servo_initialized && camera_parameters_loaded && request_message == control_message)
               {       
                    ROS_INFO("Initializing servo. Camera are parameters loaded. Service request message was : %s", control_message.c_str());

                    // Grab image and find center of gravity as feature point. 
                    grabRectifiedImage();
                    findCogCaltab();
                    displayGrabbedImage();

                    // Check if found center of gravity is found.
                    if(cog_x > -1 && cog_y > -1)
                    {
                         // Create point from found coordinates in image.
                         vpImagePoint cog_image_coordinate = vpImagePoint (cog_x, cog_y);

                         // TODO: Display COG in image.
         
                         // Set intrinsic camera parameters, since we will have to convert image pixel 
                         // coordinates to visual features expressed in meters.
                         // vpCameraParameters(px,py,u0,v0) where:
                         //   -px = horizontal pixel size. 
                         //   -py = vertical pixel size.
                         //   -u0 = X-Coordinate of image center.
                         //   -v0 = Y-Coordinate of image center.
                         vpCameraParameters camera_params(1100, 1100, camera_parameters[8].D(), camera_parameters[9].D());
                         //vpCameraParameters camera_params(600, 600, camera_parameters[8].D(), camera_parameters[9].D());
                         //vpCameraParameters camera_params(11000, 11000, camera_parameters[8].D(), camera_parameters[9].D());
                         //vpCameraParameters camera_params(camera_parameters[6].D(), camera_parameters[7].D(), camera_parameters[8].D(), camera_parameters[9].D());
                         //vpCameraParameters camera_params ;

                         // Create a vpFeaturePoint using a vpFeaturePoint and the parameters of the camera. 
                         // The vpDot contains only the pixel coordinates of the point in an image. 
                         // Thus this method uses the camera parameters to compute the meter coordinates 
                         // in x and y in the image plane.
                         vpFeatureBuilder::create(p_cog, camera_params, cog_image_coordinate);   

                         // It is not possible to compute the depth of the point Z (meter) in the camera 
                         // frame in the vpFeatureBuilder above.  
                         // This coordinate is needed in vpFeaturePoint to compute the interaction matrix. 
                         p_cog.set_Z(1.0);  

                         // Sets the desired position (x,y,z) of the visual feature.
                         pd_cog.buildFrom(0,0,1);

                         // Define the task: eye-in-hand. 
                         // The robot is hence controlled in the camera frame.
                         task.setServo(vpServo::EYEINHAND_CAMERA) ;

                         // The result should be a point on a point.
                         task.addFeature(p_cog,pd_cog) ;

                         // Set the gain of the servo task: rate of change.
                         task.setLambda(0.8) ;

                         // Display task information.
                         task.print();

                         // Make sure Baxter accepts velocity control. 
                         // TODO: BAXTER: robot.setRobotState(vpRobot::STATE_VELOCITY_CONTROL) ;

                         // The servo loop will start at iteration zero.
                         iteration = 0;
                         servo_initialized = true;
                         ROS_INFO("Servo initialized.");
                    }
                    else
                    {
                         ROS_INFO("Servo not initialized : center of gravity not found in image.");                         
                         servo_initialized = false;
                    }
               }  
               else
               {
                    // When initialized, perform servo loop.
                    ROS_INFO("Performing servo loop iteration : %d", iteration);
                    std::string control_message = "cycle";
                    if(servo_initialized && request_message == control_message)
                    {
                         // Grab image and find center of gravity as feature point. 
                         grabRectifiedImage();
                         findCogCaltab();
                         displayGrabbedImage();
                         
                         // Check if found center of gravity is found.
                         if(cog_x > -1 && cog_y > -1)
                         {
                              // Create point from found coordinates in image.
                              vpImagePoint cog_image_coordinate = vpImagePoint (cog_x, cog_y);

                              // TODO: Display COG in image.
              
                              // Set intrinsic camera parameters, since we will have to convert image pixel 
                              // coordinates to visual features expressed in meters.
                              // vpCameraParameters(px,py,u0,v0) where:
                              //   -px = horizontal pixel size. 
                              //   -py = vertical pixel size.
                              //   -u0 = X-Coordinate of image center.
                              //   -v0 = Y-Coordinate of image center.
                              vpCameraParameters camera_params(1100, 1100, camera_parameters[8].D(), camera_parameters[9].D());
                              //vpCameraParameters camera_params(600, 600, camera_parameters[8].D(), camera_parameters[9].D());
                              //vpCameraParameters camera_params(11000, 11000, camera_parameters[8].D(), camera_parameters[9].D());
                              //vpCameraParameters camera_params(camera_parameters[6].D(), camera_parameters[7].D(), camera_parameters[8].D(), camera_parameters[9].D());
                              //vpCameraParameters camera_params ;

                              // Create a vpFeaturePoint using a vpFeaturePoint and the parameters of the camera. 
                              // The vpDot contains only the pixel coordinates of the point in an image. 
                              // Thus this method uses the camera parameters to compute the meter coordinates 
                              // in x and y in the image plane.
                              vpFeatureBuilder::create(p_cog, camera_params, cog_image_coordinate);   

                              // It is not possible to compute the depth of the point Z (meter) in the camera 
                              // frame in the vpFeatureBuilder above.  
                              // This coordinate is needed in vpFeaturePoint to compute the interaction matrix. 
                              p_cog.set_Z(1.0);      

                              // Compute the visual servoing velocity vector.
                              vpColVector v = task.computeControlLaw();

                              // Get feature error (s-s*) for the feature point. For this feature
                              // point, we have 2 errors (along x and y axis).
                              // This error is expressed in meters in the camera frame
                              vpColVector error = task.getError(); 
                              ROS_INFO("Feature error (x,y): (%0.2f , %0.2f)", error[0], error[1]);

                              // Fill and send velocity vector as response to this service.
                              std::vector<double> velocity_vector(6);
                              velocity_vector[0] = v.operator[](0); 
                              velocity_vector[1] = v.operator[](1); 
                              velocity_vector[2] = v.operator[](2); 
                              velocity_vector[3] = v.operator[](3); 
                              velocity_vector[4] = v.operator[](4); 
                              velocity_vector[5] = v.operator[](5); 
                                   
                              // Send velocity vecotor as a response.
                              res.servo_velocity_vector = velocity_vector;
		                    ROS_INFO("Velocity vector has been sent: %f %f %f %f %f %f", velocity_vector[0], velocity_vector[1], velocity_vector[2], velocity_vector[3], velocity_vector[4], velocity_vector[5]);

                              // End this servo iteration.  
                              iteration++;
                              ROS_INFO("Servo iteration performed, velocity vector send.");
                         }
                         else
                         {
                              ROS_INFO("Servo iteration failed : could not find center of gravity. Retry.");                                                       
                              
                              // Fill and send empty velocity vector as response to this service.
                              std::vector<double> velocity_vector(6);
                              res.servo_velocity_vector = velocity_vector; 
                         }
                    }
                    else
                    {
                          if(!servo_initialized)
                          {
                              ROS_INFO("Servo function not yet initialized.");
                          }
                          if(request_message != control_message )
                          {
                              ROS_INFO("Wrong request message, use: %s", control_message.c_str() );
                          }
                    }
               }       
          }
          catch(vpException e) 
          {
               ROS_ERROR("Could not calculate velocity vector in getVelocityVector_Point");
          }     
     	program_lock = false;
		return true;
     }
	else
	{
		ROS_INFO("Visual servo calculation currently already executing and service (getVelocityVector_Point) is therefore locked.");
		return false;
	}

}
 
 
          			          
/***************************************************************************************************
 *
 *   Service for velocity vector from image based visual servo control, using grabbed images
 *   and calculated feature points from a calibration plate in the image.
 *
 **************************************************************************************************/	          
bool getVelocityVector_CalTab(visual_servo_control::request_servo_velocity_vector::Request &req, visual_servo_control::request_servo_velocity_vector::Response &res)
{
	// This part of the function gets locked if it is still calculating the next velocity
	// vector in the servo application. Hence, this service will return false if it is still busy. 
	ROS_INFO("Service called (getVelocityVector_CalTab)");
	std::string request_message = req.request_message.c_str();
	if(!program_lock)
	{
	     ROS_INFO("Program not locked, starting getVelocityVector_CalTab");
		program_lock = true;
          try {
               // If the servo system is not yet initialized, then initialize global variables.
               // The control message is compared to the incoming request message.
               std::string control_message = "initialize";
               if(!servo_initialized && camera_parameters_loaded && request_message == control_message)
               {       
                    ROS_INFO("Initializing servo, camera parameters loaded, request message: %s", control_message.c_str());
                    // We define four 3D points that represent the corners of a 7.5cm by 7.5cm square.              
                    point[0].setWorldCoordinates(-0.375,-0.375, 0);
                    point[1].setWorldCoordinates( 0.375,-0.375, 0);
                    point[2].setWorldCoordinates( 0.375, 0.375, 0);
                    point[3].setWorldCoordinates(-0.375, 0.375, 0);
                    
                    // These are actually the desired features.
                    vpFeatureBuilder::create(pd[0], point[0]);
                    vpFeatureBuilder::create(pd[1], point[1]);
                    vpFeatureBuilder::create(pd[2], point[2]);
                    vpFeatureBuilder::create(pd[3], point[3]);
                  
                    // Set intrinsic camera parameters, since we will have to convert image pixel 
                    // coordinates to visual features expressed in meters.
                    // vpCameraParameters(px,py,u0,v0) where:
                    //   -px = horizontal pixel size. 
                    //   -py = vertical pixel size.
                    //   -u0 = X-Coordinate of image center.
                    //   -v0 = Y-Coordinate of image center.
                    vpCameraParameters camera_params(camera_parameters[7].D(), camera_parameters[8].D(), camera_parameters[9].D(), camera_parameters[10].D());

                    
                    // Output the coordinates as markers for RVIZ to visualize.
                    for (int i = 0 ; i < 4 ; i++) 
                    {
                       visualization_msgs::Marker marker;                  
                       marker.header.frame_id     = "/base";
                       marker.header.stamp        = ros::Time::now();
                       marker.ns                  = ros::this_node::getName().c_str();
                       marker.id                  = i;
                       marker.type                = visualization_msgs::Marker::CYLINDER;
                       marker.action              = visualization_msgs::Marker::ADD;
                       marker.pose.position.x     = point[i].get_oX();
                       marker.pose.position.y     = point[i].get_oY();
                       marker.pose.position.z     = point[i].get_oZ();           
                       marker.pose.orientation.x  = 0.0;
                       marker.pose.orientation.y  = 0.0;
                       marker.pose.orientation.z  = 0.0;
                       marker.pose.orientation.w  = 1.0;
                       marker.scale.x             = 0.05;
                       marker.scale.y             = 0.05;
                       marker.scale.z             = 0.001;
                       marker.color.r             = 1.0f;
                       marker.color.g             = 0.0f;
                       marker.color.b             = 0.0f;
                       marker.color.a             = 1.0;
                       goal_marker_publisher.publish(marker);
                       // A very short sleep is required otherwise only 
                       // a part of the markers are published.
                       ros::Duration(0.001).sleep();
                    }     
                    
                    // The instantiation of the visual servo task is done with the next lines. 
                    // We initialize the task as an eye in hand visual servo. Resulting velocities computed 
                    // by the controller are those that should be applied in the camera frame: Vc 
                    // The interaction matrix will be computed from the current visual features. Thus they 
                    // need to be updated at each iteration of the control loop. Finally, the constant gain 
                    // lambda is set to 0.5. 
                    task.setServo(vpServo::EYEINHAND_CAMERA);
                    task.setInteractionMatrixType(vpServo::CURRENT);
                    task.setLambda(0.5);
                    
                    // It is now time to define four visual features as points in the image-plane. 
                    // To this end we instantiate the vpFeaturePoint class. The current point feature s is 
                    // implemented in p[i]. The desired point feature s* is implemented in pd[i]. 
                    // Each feature is obtained by computing the position of the 3D points in the corresponding 
                    // camera frame, and then by applying the perspective projection. Once current and desired 
                    // features are created, they are added to the visual servo task. 
                  
                    grabRectifiedImage();
                    findPoints();
                    displayGrabbedImage();
                    
                    vpImagePoint feature_1_image_coordinate = vpImagePoint (point_1_x, point_1_y);
                    vpImagePoint feature_2_image_coordinate = vpImagePoint (point_2_x, point_2_y);
                    vpImagePoint feature_3_image_coordinate = vpImagePoint (point_3_x, point_3_y);
                    vpImagePoint feature_4_image_coordinate = vpImagePoint (point_4_x, point_4_y);
                                                        
                                            
                    // Create a vpFeaturePoint using a vpDot and the parameters of the camera. 
                    // The vpDot contains only the pixel coordinates of the point in an image. 
                    // Thus this method uses the camera parameters to compute the meter coordinates 
                    // in x and y in the image plan. Those coordinates are stored in the vpFeaturePoint.
                    vpFeatureBuilder::create(p[0], camera_params, feature_1_image_coordinate);
                    vpFeatureBuilder::create(p[1], camera_params, feature_2_image_coordinate);
                    vpFeatureBuilder::create(p[2], camera_params, feature_3_image_coordinate);
                    vpFeatureBuilder::create(p[3], camera_params, feature_4_image_coordinate);

                    task.addFeature(p[0], pd[0]);
                    task.addFeature(p[1], pd[1]);
                    task.addFeature(p[2], pd[2]);
                    task.addFeature(p[3], pd[3]);

                    // From the initial position wMc of the camera and the position of the object 
                    // previously fixed in the camera frame cMo, we compute the position of the object in the 
                    // world frame wMo. Since in our simulation the object is static, wMo will remain unchanged.
                    
                    // TODO: get position robot/camera from baxter. now hardcoded for testing.
                    //robot.getPosition(wMc);
                    
                    vpHomogeneousMatrix wMc(0, 0, 0.30, 0, 0, 0); 
                    wMo = wMc * cMo;
                    
                    // Update simulated camera pose to starting pose. 
                    vpTranslationVector sim_cam_translation;
                    vpQuaternionVector  sim_cam_rotation;    
                    cMo.extract(sim_cam_translation);
                    cMo.extract(sim_cam_rotation);
                    
                    //ROS_INFO("Quaternion.x: %f", sim_cam_rotation.x());
                    //ROS_INFO("Quaternion.y: %f", sim_cam_rotation.y());
                    //ROS_INFO("Quaternion.z: %f", sim_cam_rotation.z());
                    //ROS_INFO("Quaternion.w: %f", sim_cam_rotation.w());
                   
                    simulated_camera_position = tf::Vector3(sim_cam_translation[0], sim_cam_translation[1], sim_cam_translation[2]);
                    simulated_camera_rotation = tf::Quaternion(sim_cam_rotation.x(), sim_cam_rotation.y(), sim_cam_rotation.z(), sim_cam_rotation.w());

                    // The servo loop will start at iteration zero.
                    iteration = 0;
              			     
                    servo_initialized = true;
                    ROS_INFO("Servo initialized.");
               }  
               else
               {
                    // When initialized, perform servo loop.
                    ROS_INFO("Performing servo loop iteration : %d", iteration);
                    std::string control_message = "cycle";
                    if(simulation_initialized && request_message == control_message)
                    {
                         // Now we can enter in the visual servo loop. When a velocity is applied to our free 
                         // flying camera, the position of the camera frame wMc will evolve wrt the world frame. 
                         // From this position we compute the position of object in the new camera frame.      
                        
                         // Get robot current pose. Should be cast to a vpHomogeneousMatrix.
                         robot.getPosition(wMc);
                         
                         // from the initial position wMc of the camera and the position of the object previously 
                         // fixed in the camera frame cMo, we compute the position of the object in the world 
                         // frame wMo. Since in our simulation the object is static, wMo will remain unchanged.
                         cMo = wMc.inverse() * wMo;
                         
                         // Take images and find feature points.
                         grabRectifiedImage();
                         findPoints();
                         displayGrabbedImage();
                         
                         vpImagePoint feature_1_image_coordinate = vpImagePoint (point_1_x, point_1_y);
                         vpImagePoint feature_2_image_coordinate = vpImagePoint (point_2_x, point_2_y);
                         vpImagePoint feature_3_image_coordinate = vpImagePoint (point_3_x, point_3_y);
                         vpImagePoint feature_4_image_coordinate = vpImagePoint (point_4_x, point_4_y);
                                                 
                         // Set intrinsic camera parameters, since we will have to convert image pixel 
                         // coordinates to visual features expressed in meters.
                         // vpCameraParameters(px,py,u0,v0) where:
                         //   -px = horizontal pixel size. 
                         //   -py = vertical pixel size.
                         //   -u0 = X-Coordinate of image center.
                         //   -v0 = Y-Coordinate of image center.
                         vpCameraParameters camera_params(camera_parameters[7].D(), camera_parameters[8].D(), camera_parameters[9].D(), camera_parameters[10].D());

                                                 
                         // Create a vpFeaturePoint using a vpDot and the parameters of the camera. 
                         // The vpDot contains only the pixel coordinates of the point in an image. 
                         // Thus this method uses the camera parameters to compute the meter coordinates 
                         // in x and y in the image plan. Those coordinates are stored in the vpFeaturePoint.
                         vpFeatureBuilder::create(p[0], camera_params, feature_1_image_coordinate);
                         vpFeatureBuilder::create(p[1], camera_params, feature_2_image_coordinate);
                         vpFeatureBuilder::create(p[2], camera_params, feature_3_image_coordinate);
                         vpFeatureBuilder::create(p[3], camera_params, feature_4_image_coordinate);

                         // It is not possible to compute the depth of the point Z (meters) in the camera frame 
                         // This coordinate is needed in vpFeaturePoint to compute the interaction matrix. 
                         // So this value must be computed / estimated too. 
                         // Furthermore we need to update Z. This is done by projecting each 3D point of the 
                         // target in the camera frame.
                              
                         // TODO: estimateDepthFromImageOrSLAM();
                              
                         vpColVector cP_1;
                         vpColVector cP_2;
                         vpColVector cP_3;
                         vpColVector cP_4;

                         point[0].changeFrame(cMo, cP_1);
                         point[1].changeFrame(cMo, cP_2);
                         point[2].changeFrame(cMo, cP_3);
                         point[3].changeFrame(cMo, cP_4);
                         
                         p[0].set_Z(cP_1[2]);
                         p[1].set_Z(cP_2[2]);
                         p[2].set_Z(cP_3[2]);
                         p[3].set_Z(cP_4[2]);
                         
                         ROS_INFO("Quaternion.w: %f %f %f %f", cP_1[2], cP_2[2], cP_3[2], cP_4[2] );
    
                         // Calculate velocity vector.
                         vpColVector v = task.computeControlLaw();
                         
                         // Output velocity vector.
                         //robot.setVelocity(vpRobot::CAMERA_FRAME, v);
                         
                         
                         // Fill and send velocity vector as response to this service.
                         std::vector<double> velocity_vector(6);
                         velocity_vector[0] = v.operator[](0); 
                         velocity_vector[1] = v.operator[](1); 
                         velocity_vector[2] = v.operator[](2); 
                         velocity_vector[3] = v.operator[](3); 
                         velocity_vector[4] = v.operator[](4); 
                         velocity_vector[5] = v.operator[](5); 
                              
                         // Send response.
                         res.servo_velocity_vector = velocity_vector;
		               ROS_INFO("Velocity vector has been sent: %f %f %f %f %f %f", velocity_vector[0], velocity_vector[1], velocity_vector[2], velocity_vector[3], velocity_vector[4], velocity_vector[5]);

                         // Update simulated camera pose. 
                         vpTranslationVector sim_cam_translation;
                         vpQuaternionVector  sim_cam_rotation;    
                         cMo.extract(sim_cam_translation);
                         cMo.extract(sim_cam_rotation);
                              
                         //ROS_INFO("Quaternion.x: %f", sim_cam_rotation.x());
                         //ROS_INFO("Quaternion.y: %f", sim_cam_rotation.y());
                         //ROS_INFO("Quaternion.z: %f", sim_cam_rotation.z());
                         //ROS_INFO("Quaternion.w: %f", sim_cam_rotation.w());
                             
                         simulated_camera_position = tf::Vector3(sim_cam_translation[0], sim_cam_translation[1], sim_cam_translation[2]);
                         simulated_camera_rotation = tf::Quaternion(sim_cam_rotation.x(), sim_cam_rotation.y(), sim_cam_rotation.z(), sim_cam_rotation.w());
                         
                         iteration++;
                         
                         ROS_INFO("Servo iteration performed, velocity vector send.");
                    }
                    else
                    {
                          if(!servo_initialized)
                          {
                              ROS_INFO("Servo not yet initialized.");
                          }
                          if(request_message != control_message )
                          {
                              ROS_INFO("Wrong request message, use: %s", control_message.c_str() );
                          }
                    }
               }       
          }
          catch(vpException e) 
          {
               ROS_INFO("Could not perform servo control.");
          }     
     	program_lock = false;
		return true;
     }
	else
	{
		ROS_INFO("Visual servo calculation currently already executing and service is therefore locked.");
		return false;
	}
}         			          
          		
          			         
          			                   			          
          			          
/***************************************************************************************************
 *
 *   This service can be called to test an image based visual servo control simulation.
 *   Each call to this service returns the next velocity vector.
 *
 **************************************************************************************************/	          
bool simulateVelocityVectorCalculation(visual_servo_control::request_servo_velocity_vector::Request &req, visual_servo_control::request_servo_velocity_vector::Response &res)
{
	// This part of the function gets locked if it is still calculating the next velocity
	// vector in the servo application. Hence, this service will return false if it is still busy. 
	ROS_INFO("Service called (simulateVelocityVectorCalculation)");
	std::string request_message = req.request_message.c_str();
	if(!program_lock)
	{
	     ROS_INFO("Program not locked, starting simulateVelocityVectorCalculation");
		program_lock = true;
          try {
               // If the servo simulation is not yet initialized, then initialize global variables.
               // The control message is compared to the incoming request message.
               std::string control_message = "initialize";
               if(!simulation_initialized && request_message == control_message)
               {                    
                    ROS_INFO("Initializaing simulation");
                    // Then we define four 3D points that represent the corners of a 20cm by 20cm square. 
                    point[0].setWorldCoordinates(-0.1,-0.1, 0);
                    point[1].setWorldCoordinates( 0.1,-0.1, 0);
                    point[2].setWorldCoordinates( 0.1, 0.1, 0);
                    point[3].setWorldCoordinates(-0.1, 0.1, 0);
                  
                    // Output the coordinates as markers for RVIZ to visualize.
                    for (int i = 0 ; i < 4 ; i++) 
                    {
                       visualization_msgs::Marker marker;                  
                       marker.header.frame_id     = "/world_frame";
                       marker.header.stamp        = ros::Time::now();
                       marker.ns                  = ros::this_node::getName().c_str();
                       marker.id                  = i;
                       marker.type                = visualization_msgs::Marker::CYLINDER;
                       marker.action              = visualization_msgs::Marker::ADD;
                       marker.pose.position.x     = point[i].get_oX();
                       marker.pose.position.y     = point[i].get_oY();
                       marker.pose.position.z     = point[i].get_oZ();           
                       marker.pose.orientation.x  = 0.0;
                       marker.pose.orientation.y  = 0.0;
                       marker.pose.orientation.z  = 0.0;
                       marker.pose.orientation.w  = 1.0;
                       marker.scale.x             = 0.05;
                       marker.scale.y             = 0.05;
                       marker.scale.z             = 0.001;
                       marker.color.r             = 1.0f;
                       marker.color.g             = 0.0f;
                       marker.color.b             = 0.0f;
                       marker.color.a             = 1.0;
                       goal_marker_publisher.publish(marker);
                       // A very short sleep is required otherwise only 
                       // a part of the markers are published.
                       ros::Duration(0.001).sleep();
                    }
                    
                    
                    // The instantiation of the visual servo task is done with the next lines. 
                    // We initialize the task as an eye in hand visual servo. Resulting velocities computed 
                    // by the controller are those that should be applied in the camera frame: Vc 
                    // The interaction matrix will be computed from the current visual features. Thus they 
                    // need to be updated at each iteration of the control loop. Finally, the constant gain 
                    // lambda is set to 0.5. 
                    task.setServo(vpServo::EYEINHAND_CAMERA);
                    task.setInteractionMatrixType(vpServo::CURRENT);
                    task.setLambda(0.5);
                    
                    // It is now time to define four visual features as points in the image-plane. 
                    // To this end we instantiate the vpFeaturePoint class. The current point feature s is 
                    // implemented in p[i]. The desired point feature s* is implemented in pd[i]. 
                    // Each feature is obtained by computing the position of the 3D points in the corresponding 
                    // camera frame, and then by applying the perspective projection. Once current and desired 
                    // features are created, they are added to the visual servo task. 
                    for (unsigned int i = 0 ; i < 4 ; i++) 
                    {
                         point[i].track(cdMo);
                         vpFeatureBuilder::create(pd[i], point[i]);
                         point[i].track(cMo);
                         vpFeatureBuilder::create(p[i], point[i]);
                         task.addFeature(p[i], pd[i]);
                    }
                    
                    // Here we also specify the sampling time to 0.040 seconds. When a velocity is applied 
                    // to the camera, this time will be used by the exponential map to determine the next 
                    // position of the camera.
                    robot.setSamplingTime(0.040);
    
                    // From the initial position wMc of the camera and the position of the object 
                    // previously fixed in the camera frame cMo, we compute the position of the object in the 
                    // world frame wMo. Since in our simulation the object is static, wMo will remain unchanged.
                    robot.getPosition(wMc);
                    wMo = wMc * cMo;
                    
                    // Update simulated camera pose to starting pose. 
                    vpTranslationVector sim_cam_translation;
                    vpQuaternionVector  sim_cam_rotation;    
                    cMo.extract(sim_cam_translation);
                    cMo.extract(sim_cam_rotation);
                    
                    //ROS_INFO("Quaternion.x: %f", sim_cam_rotation.x());
                    //ROS_INFO("Quaternion.y: %f", sim_cam_rotation.y());
                    //ROS_INFO("Quaternion.z: %f", sim_cam_rotation.z());
                    //ROS_INFO("Quaternion.w: %f", sim_cam_rotation.w());
                   
                    simulated_camera_position = tf::Vector3(sim_cam_translation[0], sim_cam_translation[1], sim_cam_translation[2]);
                    simulated_camera_rotation = tf::Quaternion(sim_cam_rotation.x(), sim_cam_rotation.y(), sim_cam_rotation.z(), sim_cam_rotation.w());

                    // The servo loop will start at iteration zero.
                    iteration = 0;
              			     
                    simulation_initialized = true;
               }  
               else
               {
                    // When initialized, perform servo loop.
                    std::string control_message = "cycle";
                    if(simulation_initialized && request_message == control_message)
                    {
                         // Now we can enter in the visual servo loop. When a velocity is applied to our free 
                         // flying camera, the position of the camera frame wMc will evolve wrt the world frame. 
                         // From this position we compute the position of object in the new camera frame.      
                         ROS_INFO("Simulating at iteration: %d", iteration);
                         if(iteration < 150)
                         {
                              robot.getPosition(wMc);
                              
                              // From the initial position wMc of the camera and the position of the object previously 
                              // fixed in the camera frame cMo, we compute the position of the object in the world 
                              // frame wMo. Since in our simulation the object is static, wMo will remain unchanged.
                              cMo = wMc.inverse() * wMo;
                              
                              // The current visual features are then updated by projecting the 3D points in the 
                              // image-plane associated to the new camera location cMo. 
                              for (unsigned int i = 0 ; i < 4 ; i++) 
                              {
                                   point[i].track(cMo);
                                   vpFeatureBuilder::create(p[i], point[i]);
                              }
                              // Finally, the velocity skew v is computed. 
                              vpColVector v = task.computeControlLaw();
                              
                              // This 6-dimension velocity vector is then applied to the camera.
                              robot.setVelocity(vpRobot::CAMERA_FRAME, v);
                              
                              // Print detailed info about the current task.
                              //task.print();
                              
                              // Fill and send velocity vector as response to this service.
                              std::vector<double> velocity_vector(6);
                              velocity_vector[0] = v.operator[](0); 
                              velocity_vector[1] = v.operator[](1); 
                              velocity_vector[2] = v.operator[](2); 
                              velocity_vector[3] = v.operator[](3); 
                              velocity_vector[4] = v.operator[](4); 
                              velocity_vector[5] = v.operator[](5); 
                              
                              // Send response.
                              res.servo_velocity_vector = velocity_vector;
		                    ROS_INFO("Velocity vector has been sent: %f %f %f %f %f %f", velocity_vector[0], velocity_vector[1], velocity_vector[2], velocity_vector[3], velocity_vector[4], velocity_vector[5]);

                              // Update simulated camera pose. 
                              vpTranslationVector sim_cam_translation;
                              vpQuaternionVector  sim_cam_rotation;    
                              cMo.extract(sim_cam_translation);
                              cMo.extract(sim_cam_rotation);
                              
                              //ROS_INFO("Quaternion.x: %f", sim_cam_rotation.x());
                              //ROS_INFO("Quaternion.y: %f", sim_cam_rotation.y());
                              //ROS_INFO("Quaternion.z: %f", sim_cam_rotation.z());
                              //ROS_INFO("Quaternion.w: %f", sim_cam_rotation.w());
                             
                              simulated_camera_position = tf::Vector3(sim_cam_translation[0], sim_cam_translation[1], sim_cam_translation[2]);
                              simulated_camera_rotation = tf::Quaternion(sim_cam_rotation.x(), sim_cam_rotation.y(), sim_cam_rotation.z(), sim_cam_rotation.w());

                              // increase iteration for next step in the servo loop.
                              iteration++; 
                         }
                         else
                         {
                              ROS_INFO("Simulation done.");
                         
                              // Before exiting the program, we free all the memory by killing the task. 
                              task.kill();
                              
                              // We also want to reset the initialization for the next call.
                              simulation_initialized = false;
                         }
                    }
                    else
                    {
                          if(!simulation_initialized)
                          {
                              ROS_INFO("Simulation not yet initialized.");
                          }
                          if(request_message != control_message )
                          {
                              ROS_INFO("Wrong request message, use: %s", control_message.c_str() );
                          }
                    }
               }       
          }
          catch(vpException e) 
          {
               ROS_INFO("Could not simulate image based visual servo control.");
          }     
     	program_lock = false;
		return true;
     }
	else
	{
		ROS_INFO("Visual servo calculation currently already executing and service is therefore locked.");
		return false;
	}
}         			          
          			            


/***************************************************************************************************
 *
 *	Initializes the camera by calling the corresponding hdvp function. 
 *   The function is initialized here and has the following inputs and output:
 *
 *   Input
 *        - Exposure
 *        - Gain
 *        - GainR
 *        - GainG
 *        - GainB
 
 *        - CameraParametersPath : path to the .cam file holding the camera parameters, defined
 *                                 in launch file and loaded in global parameter camera_parameters_path
 *        
 *        
 *   Output
 *        - AcqHandle : handle for image acquisition, to save for global use.
 *
 *        - CamParam : camera parameters read from file specified in launchfile.
 *                     More information about paremeters in the array, can be found
 *                     here: http://www.halcon.com/download/reference/camera_calibration.html
 *
 *                         [0]  F       Focal length.
 *                         [1]  K1
 *                         [2]  K2
 *                         [3]  K3
 *                         [4]  P1
 *                         [5]  P2
 *                         [6]  Sx      Horizontal distance between two neighboring pixel cells.
 *                         [7]  Sy      Horizontal distance between two neighboring pixel cells.
 *                         [8]  Cx      X-Coordinate of image center.
 *                         [9] Cy      Y-Coordinate of image center.
 *                         [10] Iw      Image Width.
 *                         [11] Ih      Image Height.
 *
 **************************************************************************************************/
void initializeCamera()
{
     // Defines the name of the .hdvp function that is run.
     std::string procedure_name = initialize_camera_function;
     try
     {          
          // Initialize the function.
          ROS_INFO("Initializing HDev function %s.hdvp", procedure_name.c_str());
          HDevEngineCpp::HDevProcedure proc(procedure_name.c_str());
          HDevEngineCpp::HDevProcedureCall proc_call(proc);

          // Define control parameters.
          HalconCpp::HTuple Exposure    = 100;
          HalconCpp::HTuple Gain        =  16;
          HalconCpp::HTuple GainR       =  10;
          HalconCpp::HTuple GainG       =  10;
          HalconCpp::HTuple GainB       =  24;
          
          HalconCpp::HTuple CameraParametersPath = camera_parameters_path.c_str();
                  
          // Set control parameters in .hdvp function.
          proc_call.SetInputCtrlParamTuple("Exposure"  , Exposure);
          proc_call.SetInputCtrlParamTuple("Gain"      , Gain);
          proc_call.SetInputCtrlParamTuple("GainR"     , GainR);
          proc_call.SetInputCtrlParamTuple("GainG"     , GainG);
          proc_call.SetInputCtrlParamTuple("GainB"     , GainB);
          
          proc_call.SetInputCtrlParamTuple("CameraParametersPath", CameraParametersPath);
     
          //Execute and time the function.
          ROS_INFO("Executing HDev function %s.hdvp", procedure_name.c_str());
          double begin_time = ros::Time::now().toNSec();
          proc_call.Execute();
          double end_time   = ros::Time::now().toNSec();
          ROS_INFO("Succesfully executed HDev function %s.hdvp", procedure_name.c_str());
          ROS_INFO("Execution time : %.3f seconds.", (end_time-begin_time)/1000000000 );
          
          // Get aqcuisition handle and save in global variable.
          proc_call.GetOutputCtrlParamTuple("AcqHandle", &camera_acquisition_handle);
          ROS_INFO("AcqHandle # : %ld",camera_acquisition_handle[0].L());
          
          // Get camera parameters and save in global variable.
          proc_call.GetOutputCtrlParamTuple("CamParam", &camera_parameters);
          camera_parameters_loaded = true;
     }
	catch (HDevEngineCpp::HDevEngineException& hdev_exception)
	{
		ROS_INFO("Failed execution of HDev function %s.hdvp", procedure_name.c_str());
		ROS_INFO("Error category: %d : %s", 	hdev_exception.Category(),hdev_exception.CategoryText());
		ROS_INFO("Error number: %d",		     hdev_exception.HalconErrNum());
		ROS_INFO("Procedure: %s",		     hdev_exception.ExecProcedureName());
		ROS_INFO("Line: %d : %s",		     hdev_exception.ProgLineNum(),hdev_exception.ProgLineName());
	}
}





/***************************************************************************************************
 *
 *	Grabs the next image using a .hdvp function
 *
 *   Input
 *        - AcqHandle : handle for image acquisition, use the global camera_acquisition_handle.
 *
 *        - CamParam : camera parameters. 
 *        
 *   Output
 *        - ImageRectified : resized and rectified grabbed image. 
 *
 **************************************************************************************************/
void grabRectifiedImage()
{
     // Defines the name of the .hdvp function that is run.
     std::string procedure_name = grab_rectified_image_function;
     try
     {          
          // Initialize the function.
          ROS_INFO("Initializing HDev function %s.hdvp", procedure_name.c_str());
          HDevEngineCpp::HDevProcedure proc(procedure_name.c_str());
          HDevEngineCpp::HDevProcedureCall proc_call(proc);
        
          // Set control parameters in .hdvp function.
          proc_call.SetInputCtrlParamTuple("CamParam", camera_parameters);
          proc_call.SetInputCtrlParamTuple("AcqHandle", camera_acquisition_handle);
   
          //Execute and time the function.
          ROS_INFO("Executing HDev function %s.hdvp", procedure_name.c_str());
          double begin_time = ros::Time::now().toNSec();
          proc_call.Execute();
          double end_time   = ros::Time::now().toNSec();
          ROS_INFO("Succesfully executed HDev function %s.hdvp", procedure_name.c_str());
          ROS_INFO("Execution time : %.3f seconds.", (end_time-begin_time)/1000000000 );
          
          // Get image and camera parameters and save in global variable.
          last_image = proc_call.GetOutputIconicParamObject("ImageRectified");
     }
	catch (HDevEngineCpp::HDevEngineException& hdev_exception)
	{
		ROS_INFO("Failed execution of HDev function %s.hdvp", procedure_name.c_str());
		ROS_INFO("Error category: %d : %s", 	hdev_exception.Category(),hdev_exception.CategoryText());
		ROS_INFO("Error number: %d",		     hdev_exception.HalconErrNum());
		ROS_INFO("Procedure: %s",		     hdev_exception.ExecProcedureName());
		ROS_INFO("Line: %d : %s",		     hdev_exception.ProgLineNum(),hdev_exception.ProgLineName());
	}
}



/***************************************************************************************************
 *
 *	Finds 4 image features using a .hdvp function
 *
 *   Input
 *        - ImageRectified : resized and rectified grabbed image. 
 *
 *   Output
 *        - point_1_x 
 *        - point_1_y 
 *    
 *        - point_2_x 
 *        - point_2_y 
 *    
 *        - point_3_x 
 *        - point_3_y 
 *    
 *        - point_4_x 
 *        - point_4_y 
 *
 **************************************************************************************************/
void findPoints()
{
     // Defines the name of the .hdvp function that is run.
     std::string procedure_name = find_points_function;
     try
     {          
          // Initialize the function.
          ROS_INFO("Initializing HDev function %s.hdvp", procedure_name.c_str());
          HDevEngineCpp::HDevProcedure proc(procedure_name.c_str());
          HDevEngineCpp::HDevProcedureCall proc_call(proc);
        
          // Set control parameters in .hdvp function.
          //proc_call.SetInputCtrlParamTuple("WindowHandle", window_handle);
          proc_call.SetInputIconicParamObject("Image", last_image);
   
          // Execute and time the function.
          ROS_INFO("Executing HDev function %s.hdvp", procedure_name.c_str());
          double begin_time = ros::Time::now().toNSec();
          proc_call.Execute();
          double end_time   = ros::Time::now().toNSec();
          ROS_INFO("Succesfully executed HDev function %s.hdvp", procedure_name.c_str());
          ROS_INFO("Execution time : %.3f seconds.", (end_time-begin_time)/1000000000 );
          
          // Get feature points and save globally.
          proc_call.GetOutputCtrlParamTuple("point_1_x",&point_1_x);
          proc_call.GetOutputCtrlParamTuple("point_2_x",&point_2_x);
          proc_call.GetOutputCtrlParamTuple("point_3_x",&point_3_x);
          proc_call.GetOutputCtrlParamTuple("point_4_x",&point_4_x);
          proc_call.GetOutputCtrlParamTuple("point_1_y",&point_1_y);
          proc_call.GetOutputCtrlParamTuple("point_2_y",&point_2_y);
          proc_call.GetOutputCtrlParamTuple("point_3_y",&point_3_y);
          proc_call.GetOutputCtrlParamTuple("point_4_y",&point_4_y);
          
          ROS_INFO("Feature points:");
          ROS_INFO("P1x , P1y (%0.0f,%0.0f)",point_1_x[0].D(),point_1_y[0].D());
          ROS_INFO("P2x , P2y (%0.0f,%0.0f)",point_2_x[0].D(),point_2_y[0].D());
          ROS_INFO("P3x , P3y (%0.0f,%0.0f)",point_3_x[0].D(),point_3_y[0].D());
          ROS_INFO("P4x , P4y (%0.0f,%0.0f)",point_4_x[0].D(),point_4_y[0].D());

     }
	catch (HDevEngineCpp::HDevEngineException& hdev_exception)
	{
		ROS_INFO("Failed execution of HDev function %s.hdvp", procedure_name.c_str());
		ROS_INFO("Error category: %d : %s", 	hdev_exception.Category(),hdev_exception.CategoryText());
		ROS_INFO("Error number: %d",		     hdev_exception.HalconErrNum());
		ROS_INFO("Procedure: %s",		     hdev_exception.ExecProcedureName());
		ROS_INFO("Line: %d : %s",		     hdev_exception.ProgLineNum(),hdev_exception.ProgLineName());
	}
}





/***************************************************************************************************
 *
 *	Finds "Center of Gravity" of a "Calibration Plate" in an image using a .hdvp function.
 *
 *   Note that the calibration plate description file path is currently hardcoded in the hdvp function.
 *
 *   Input
 *        - Image : image containing a Halcon calibration plate. 
 *
 *   Output
 *        - cog_x 
 *        - cog_y 
 *
 **************************************************************************************************/
void findCogCaltab()
{
     // Defines the name of the .hdvp function that is run.
     std::string procedure_name = find_cog_caltab_function;
     try
     {          
          // Initialize the function.
          ROS_INFO("Initializing HDev function %s.hdvp", procedure_name.c_str());
          HDevEngineCpp::HDevProcedure proc(procedure_name.c_str());
          HDevEngineCpp::HDevProcedureCall proc_call(proc);
        
          // Set control parameters in .hdvp function.
          proc_call.SetInputIconicParamObject("Image", last_image);
   
          // Execute and time the function.
          ROS_INFO("Executing HDev function %s.hdvp", procedure_name.c_str());
          double begin_time = ros::Time::now().toNSec();
          proc_call.Execute();
          double end_time   = ros::Time::now().toNSec();
          ROS_INFO("Succesfully executed HDev function %s.hdvp", procedure_name.c_str());
          ROS_INFO("Execution time : %.3f seconds.", (end_time-begin_time)/1000000000 );
          
          // Get feature points and save globally.
          proc_call.GetOutputCtrlParamTuple("cog_x",&cog_x);
          proc_call.GetOutputCtrlParamTuple("cog_y",&cog_y);

          ROS_INFO("Center of Gravity of Calibration Plate in Image: (%0.0f,%0.0f)", cog_x[0].D(),cog_y[0].D());
     }
	catch (HDevEngineCpp::HDevEngineException& hdev_exception)
	{
		ROS_INFO("Failed execution of HDev function %s.hdvp", procedure_name.c_str());
		ROS_INFO("Error category: %d : %s", 	hdev_exception.Category(),hdev_exception.CategoryText());
		ROS_INFO("Error number: %d",		     hdev_exception.HalconErrNum());
		ROS_INFO("Procedure: %s",		     hdev_exception.ExecProcedureName());
		ROS_INFO("Line: %d : %s",		     hdev_exception.ProgLineNum(),hdev_exception.ProgLineName());
	}
}






/***************************************************************************************************
 *
 *	Displays the last image that is stored globally using a .hdvp function.
 *
 *   Input
 *        - Image : resized and rectified grabbed image to display. 
 *
 **************************************************************************************************/
void displayGrabbedImage()
{
     // Defines the name of the .hdvp function that is run.
     std::string procedure_name = display_grabbed_image;
     try
     {          
          // Initialize the function.
          ROS_INFO("Initializing HDev function %s.hdvp", procedure_name.c_str());
          HDevEngineCpp::HDevProcedure proc(procedure_name.c_str());
          HDevEngineCpp::HDevProcedureCall proc_call(proc);
        
          // Set control parameters in .hdvp function.
          proc_call.SetInputIconicParamObject("Image", last_image);
   
          // Execute and time the function.
          ROS_INFO("Executing HDev function %s.hdvp", procedure_name.c_str());
          double begin_time = ros::Time::now().toNSec();
          proc_call.Execute();
          double end_time   = ros::Time::now().toNSec();
          ROS_INFO("Succesfully executed HDev function %s.hdvp", procedure_name.c_str());
          ROS_INFO("Execution time : %.3f seconds.", (end_time-begin_time)/1000000000 );
     }
	catch (HDevEngineCpp::HDevEngineException& hdev_exception)
	{
		ROS_INFO("Failed execution of HDev function %s.hdvp", procedure_name.c_str());
		ROS_INFO("Error category: %d : %s", 	hdev_exception.Category(),hdev_exception.CategoryText());
		ROS_INFO("Error number: %d",		     hdev_exception.HalconErrNum());
		ROS_INFO("Procedure: %s",		     hdev_exception.ExecProcedureName());
		ROS_INFO("Line: %d : %s",		     hdev_exception.ProgLineNum(),hdev_exception.ProgLineName());
	}
}






/***************************************************************************************************
 *
 *	Closes the framegrabber of the camera.
 *
 *   Input
 *        - AcqHandle : handle for image acquisition, use the global camera_acquisition_handle.
 *        
 **************************************************************************************************/
void closeFrameGrabber()
{
     // Defines the name of the .hdvp function that is run.
     std::string procedure_name = close_frame_grabber_function;
     try
     {          
          // Initialize the function.
          ROS_INFO("Initializing HDev function %s.hdvp", procedure_name.c_str());
          HDevEngineCpp::HDevProcedure proc(procedure_name.c_str());
          HDevEngineCpp::HDevProcedureCall proc_call(proc);
        
          // Set control parameters in .hdvp function.
          proc_call.SetInputCtrlParamTuple("AcqHandle", camera_acquisition_handle);
   
          //Execute and time the function.
          ROS_INFO("Executing HDev function %s.hdvp", procedure_name.c_str());
          double begin_time = ros::Time::now().toNSec();
          proc_call.Execute();
          double end_time   = ros::Time::now().toNSec();
          ROS_INFO("Succesfully executed HDev function %s.hdvp", procedure_name.c_str());
          ROS_INFO("Execution time : %.3f seconds.", (end_time-begin_time)/1000000000 );
     }
	catch (HDevEngineCpp::HDevEngineException& hdev_exception)
	{
		ROS_INFO("Failed execution of HDev function %s.hdvp", procedure_name.c_str());
		ROS_INFO("Error category: %d : %s", 	hdev_exception.Category(),hdev_exception.CategoryText());
		ROS_INFO("Error number: %d",		     hdev_exception.HalconErrNum());
		ROS_INFO("Procedure: %s",		     hdev_exception.ExecProcedureName());
		ROS_INFO("Line: %d : %s",		     hdev_exception.ProgLineNum(),hdev_exception.ProgLineName());
	}
}


/***************************************************************************************************
 *
 *        
 **************************************************************************************************/
void testF()
{
     // Defines the name of the .hdvp function that is run.
     std::string procedure_name = test;
     try
     {          
          // Initialize the function.
          ROS_INFO("Initializing HDev function %s.hdvp", procedure_name.c_str());
          HDevEngineCpp::HDevProcedure proc(procedure_name.c_str());
          HDevEngineCpp::HDevProcedureCall proc_call(proc);
        
          //Execute and time the function.
          ROS_INFO("Executing HDev function %s.hdvp", procedure_name.c_str());
          double begin_time = ros::Time::now().toNSec();
          proc_call.Execute();
          double end_time   = ros::Time::now().toNSec();
          ROS_INFO("Succesfully executed HDev function %s.hdvp", procedure_name.c_str());
          ROS_INFO("Execution time : %.3f seconds.", (end_time-begin_time)/1000000000 );
     }
	catch (HDevEngineCpp::HDevEngineException& hdev_exception)
	{
		ROS_INFO("Failed execution of HDev function %s.hdvp", procedure_name.c_str());
		ROS_INFO("Error category: %d : %s", 	hdev_exception.Category(),hdev_exception.CategoryText());
		ROS_INFO("Error number: %d",		     hdev_exception.HalconErrNum());
		ROS_INFO("Procedure: %s",		     hdev_exception.ExecProcedureName());
		ROS_INFO("Line: %d : %s",		     hdev_exception.ProgLineNum(),hdev_exception.ProgLineName());
	}
}




/***************************************************************************************************
 *
 *   Initializes the halcon procedures before they can be executed.
 *
 **************************************************************************************************/
void intializeHalconProcedures()
{
       	ROS_INFO("Initializing Halcon procedures.");
	     hdevengine.SetHDevOperatorImpl(new WindowHandlingImplementation);
	     hdevengine.SetProcedurePath(halcon_external_procedures_path.c_str());
	     ROS_INFO("External procedures path : %s", halcon_external_procedures_path.c_str());
}



/***************************************************************************************************
 *
 *   Runs the .hdev script once if initilized with function initializeHalconScript();
 *   TODO: write access function to get results.
 *
 **************************************************************************************************/
bool runHalconScript()
{
     program_lock = true;
	if(initialized)
	{
		ROS_INFO("Executing Halcon script (.hdev) at %s", halcon_script_path.c_str());
		script_results = hdev_script.Execute();
		ROS_INFO("Halcon script has been executed, results are available");
	}
	else
	{
		ROS_INFO("Halcon script not yet initialized. Not executing program at %s", halcon_script_path.c_str());
		return false;
	}
     program_lock = false;
	return true;
}



/***************************************************************************************************
 *
 *	Initializes the .hdev script by loading it into the halcon engine.
 *
 *	The program is not executed here.
 *
 **************************************************************************************************/
void initializeHalconScript()
{
	ROS_INFO("Initializing .hdev Program");

	hdevengine.SetHDevOperatorImpl(new WindowHandlingImplementation);
	hdevengine.SetProcedurePath(halcon_external_procedures_path.c_str());

	ROS_INFO("Script path (.hdev file)  : %s", halcon_script_path.c_str());
	ROS_INFO("External procedures path  : %s", halcon_external_procedures_path.c_str());

	try
	{
		hdev_script.LoadProgram(halcon_script_path.c_str());
		initialized = true;
		ROS_INFO("Halcon program initialisation succesful.");
	}
	catch (HDevEngineCpp::HDevEngineException& hdev_exception)
	{
		ROS_INFO("Halcon program initialisation NOT succesful.");
		ROS_INFO("Error category: %d : %s",hdev_exception.Category(),hdev_exception.CategoryText());
		ROS_INFO("Error number: %d",		hdev_exception.HalconErrNum());
		ROS_INFO("Procedure: %s",		hdev_exception.ExecProcedureName());
		ROS_INFO("Line: %d : %s",		hdev_exception.ProgLineNum(),hdev_exception.ProgLineName());
	}
}



/***************************************************************************************************
 *
 *	Initializes the ROS node.
 *
 *	The program path of the .hdev file that is to be executed for image acquisition is passed in 
 *	the launchfile (halcon_program_path). Similarly, if the script uses any external procedures, 
 *	a path (halcon_ext_proc_path) is also passed. The halcon script is automaticcaly initialized.
 *
 *	A service is created that can be called to return a 'velocity vector': the next step of 
 *	correction that the robot needs to perform to servo to the target. This vector is calculated
 *	by 1) taking an new image, 2) calculate the image features, 3) calculate the velocity vector
 * 	based on the image features. 
 *
 **************************************************************************************************/
int main(int argc, char **argv)
{
     // Initialize this rosnode with an empty name string. This allow the node's name
     // to be set in the launchfile so that multiple copies of this node with different
     // names can be launched. Although you would probably not run more than 1 servo node, 
     // it is good practice to initialize the ros node's name in the launch file. 
     ros::init(argc, argv, "");
     sleep(10);
     
     // The nodehandle is initilized with a tilde ("~") The tilde refers to the node handle's 
     // namespace. This could be any namespace, which is roughly equivalent to a node name. 
     // However, the tilde refers to the current node's namespace. Why is this useful? In a 
     // roslaunch file, you can pass parameters to the system. There are "global" parameters 
     // that exist in the global, or default, namespace. These fall directly inside the <launch> 
     // tag. However, you can also put parameters under a <node> tag, and these will be in the 
     // local, or private, namespace of that node.
    	ros::NodeHandle node_handle("~");
    	
    	// Parameters that are initialized at start of the ros node.
    	// TODO: these should be made specific to a function.
	program_lock             = false;
	initialized              = false;
	servo_initialized        = false;
	camera_parameters_loaded = false;

     // Get general path parameters for Halcon from ROS launch file.
     node_handle.getParam("halcon_script_path",             halcon_script_path);
    	node_handle.getParam("halcon_external_procedures_path",halcon_external_procedures_path);
    	node_handle.getParam("camera_parameters_path",         camera_parameters_path);
    	
    	// Get specific path parameters for Halcon functions that are loaded.
    	node_handle.getParam("initialize_camera_function",         initialize_camera_function);
    	node_handle.getParam("grab_rectified_image_function",      grab_rectified_image_function);
    	node_handle.getParam("display_grabbed_image",              display_grabbed_image);
    	node_handle.getParam("find_points_function",               find_points_function);
    	node_handle.getParam("find_cog_caltab_function",           find_cog_caltab_function);
    	
    	node_handle.getParam("close_frame_grabber_function",       close_frame_grabber_function);
    	node_handle.getParam("test",       test);
    		
	// You can either initialize a full halcon script or initialize a set of procedures.
	// It is recomended you write everything in procedures so you can run subroutines without
	// any initialization overhead. 
	intializeHalconProcedures(); // OR initializeHalconScript();
	
	// Initialize camera to open frame grabber and get camera parameters.	     
	initializeCamera();

     // Service for providing the main output from this node: a velocity vector.
     // Only one service can be activated at a time due to equal service names.
     velocity_vector_output_service = node_handle.advertiseService("request_servo_velocity_vector", getVelocityVector_Point); 
	//velocity_vector_output_service = node_handle.advertiseService("request_servo_velocity_vector", simulateVelocityVectorCalculation);
	//velocity_vector_output_service = node_handle.advertiseService("request_servo_velocity_vector", getVelocityVector_CalTab);
	
	// A publisher for a set of markers to visualize relevant positions in RVIZ.
	goal_marker_publisher = node_handle.advertise<visualization_msgs::Marker>( "goal_feature_markers", 1 );
		
	// Initialize frame transformation parameters for simulated camera.
     tf::TransformBroadcaster      tf_broadcaster;
     tf::Transform                 transform;
     simulated_camera_position  =  tf::Vector3(0.0, 0.0, 0.0) ;
     simulated_camera_rotation  =  tf::Quaternion(0, 0, 0) ;
     
     // Test all halcon procedures.
     //initializeCamera(); //Already done above.
     //grabRectifiedImage();
     //findPoints();
     //findCogCaltab();
     //displayGrabbedImage();
     //closeFrameGrabber();
     
     // The ROS node will in the following loop.	
     ros::Rate rate(10.0);
     while (node_handle.ok())
     {
          // Frame transformations need to be updated constantly, otherwise they will fade out of existence. 
          transform.setOrigin(simulated_camera_position);
          transform.setRotation(simulated_camera_rotation);
          tf_broadcaster.sendTransform(tf::StampedTransform(transform, ros::Time::now(), "base", "simulated_camera_frame"));
          
          // Do one spin of the rosnode, e.g. checking and executing callbacks.
          // (http://wiki.ros.org/roscpp/Overview/Callbacks%20and%20Spinning)
          ros::spinOnce();
          rate.sleep();
     }
	return 0;
}
