/*
* Software License Agreement (BSD License)
*
* Copyright (c) 2014,Ume√• University
* All rights reserved.
*
* Redistribution and use in source and binary forms, with or without
* modification, are permitted provided that the following conditions
* are met:
*
* * Redistributions of source code must retain the above copyright
* notice, this list of conditions and the following disclaimer.
* * Redistributions in binary form must reproduce the above
* copyright notice, this list of conditions and the following
* disclaimer in the documentation and/or other materials provided
* with the distribution.
* * Neither the name of Open Source Robotics Foundation nor
* the names of its contributors may be used to endorse or promote
* products derived from this software without specific prior
* written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
* "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
* LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
* FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
* COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
* INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
* BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
* LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
* CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
* LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
* ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
* POSSIBILITY OF SUCH DAMAGE.
*/

/**
 * State for moving the arm to a fruit coordinate using actionlib interface
 *
 * Author Ola Ringdahl, ringdahl@cs.umu.se
 */

#include "Pepper_MoveToVisualServoStartState.h"
#include "ros/ros.h"
#include "std_msgs/String.h"
#include "std_msgs/Bool.h"

using std::string;
using std::map;

Pepper_MoveToVisualServoStartState::Pepper_MoveToVisualServoStartState() :
    SimpleActionState("/p2pAction") // name of the actionlib server node
{
  PubManipulatorState = n.advertise<crops_msgs::manipulatorState>("setManipulatorMode", 1000);
  //check if xpc_simulator or xpcTarget Hardware should be used
  ros::param::get("/crops_manipulator_udp/xpc_target", xpc_target_);
  manipulator_state_pub_ = n.advertise<crops_msgs::manipulatorState>("setManipulatorMode", 1);

  end_effector_control = n.advertise<crops_msgs::end_effector_command>("end_effector_control", 1000);
  end_effector_feedback = n.subscribe("end_effector_status", 1,
                                      &Pepper_MoveToVisualServoStartState::ProcessEndEffectorStatus, this);

  nh_.getParam("tcp_position", tcp_pos_);
  ros::param::get("/gripperType", gripperType);
  updateTCPsettings_ = nh_.advertise<crops_msgs::tcpInfo>("tcp_info", 1);

  fruit_detected_minicam = nh_.subscribe("fruit_detected_minicam", 1000,
                                         &Pepper_MoveToVisualServoStartState::miniCamFeedbackCb, this);

  first_ = true;
  //collisionChecked = false;
  // TEST without collision
  collisionChecked = true;
  mini_cam_fruit_detected = false;

  tf::TransformListener transformation_listener(ros::Duration max_cache_time = ros::Duration(20), bool spin_thread =
                                                    true); //10.0 is the default amount of time to cache data in seconds

  // HOTFIX: hardcoded trigger topic names.
  trigger_pub_vrm_ = nh_.advertise<crops_msgs::ImageRequest>("vrm_controller_req", 1);
  trigger_pub_pmd_ = nh_.advertise<crops_msgs::ImageRequest>("pmd/img_req_topic_pmd", 1);

  // init to a default
  end_effector_status.fruit_not_removed = NULL;
  end_effector_status.gripping_failed = NULL;
  end_effector_status.fruit_removed = NULL;
  end_effector_status.cutter_ready = NULL;
  end_effector_status.gripping_successful = NULL;
  end_effector_status.gripper_ready = NULL;

  // init to a default at beginning of this state
  end_effector_command.endeffectortype = (int8_t)1; // Festo SP 2
  end_effector_command.gripper_status = false; // open gripper
  end_effector_command.cutter_status = false; // open cutter
  end_effector_command.led_status = false; // lights off
  end_effector_command.camera_status = true; // camera on;
  end_effector_command.nozzle_status = false; // no nozzle for pepper
  end_effector_command.fan_speed = 0;

  end_effector_control.publish(end_effector_command);

}

Pepper_MoveToVisualServoStartState::~Pepper_MoveToVisualServoStartState()
{

}

/**
 * Feedback from the arm
 */
void Pepper_MoveToVisualServoStartState::feedbackCb(const crops_msgs::p2pFeedbackConstPtr feedback)
{
  ROS_INFO("#GUI Progress: %.0f %%", feedback->progress * 100);
}

void Pepper_MoveToVisualServoStartState::miniCamFeedbackCb(const crops_msgs::SingleFruit::ConstPtr& msg)
{
  ROS_INFO("(Callback) Result from mini camera images analysis published.");
  mini_cam_fruit = *msg;
  mini_cam_fruit_detected = true;
}

/**
 * Load fruit coordinates from the state machine and move the arm towards it
 */
string Pepper_MoveToVisualServoStartState::execute(map<string, boost::any> * data)
{

  data_ = data;

  string state_transition;

  // Let next state know who precedes it
  std::string state_name = "PepperMoveToVisualServoStart";
  (*data)["parent_state"] = state_name;

  // Get current goal pose
  goal_ = boost::any_cast<crops_msgs::p2pGoal>((*data)["arm_goal"]);

  // Move TCP position forward to simulate start position for visual servoing.
  crops_msgs::tcpInfo msg;
  msg.tcp_tooltype = 0;
  // test gripper //msg.tcp_transform.translation.x = (double)tcp_pos_[0] - (double)0.10;
  // test gripper //msg.tcp_transform.translation.y = (double)tcp_pos_[1];
  // test gripper //msg.tcp_transform.translation.z = (double)tcp_pos_[2] + (double)0.05;

  if (gripperType == "festo")
  {
    // Festo gripper
    msg.tcp_transform.translation.x = (double)tcp_pos_[0] - 0.076;
    msg.tcp_transform.translation.y = (double)tcp_pos_[1] + 0.017; // camera ascentric
    msg.tcp_transform.translation.z = (double)tcp_pos_[2] - 0.08 + (double)0.30;
  }
  else if (gripperType == "jaws")
  {
    // WUR gripper
	// we position the VRM camera in front of the fruit. However, the coordinates we get back are based on the PMD frame
	// keep this in mind.
    msg.tcp_transform.translation.x = (double)tcp_pos_[0] - 0.052;
    msg.tcp_transform.translation.y = (double)tcp_pos_[1] + 0.0;
    msg.tcp_transform.translation.z = (double)tcp_pos_[2] - 0.114 + (double)0.30;
  }
  else
  {
    ROS_ERROR("Specified gripper type not exisiting!");
  }

  msg.tcp_transform.rotation.x = tcp_pos_[3];
  msg.tcp_transform.rotation.y = tcp_pos_[4];
  msg.tcp_transform.rotation.z = tcp_pos_[5];
  msg.tcp_transform.rotation.w = tcp_pos_[6];
  updateTCPsettings_.publish(msg);

  /*end_effector_command.gripper_status  = false;		// open gripper
   end_effector_command.cutter_status   = false;		// open cutter
   end_effector_command.led_status = true; // turn light on
   end_effector_control.publish(end_effector_command);
   */

  // When not yet checked on a collision, determine goal and perform collision detection.
  if (!collisionChecked)
  {
    // Let collision state know which state calls him.
    ROS_INFO("#GUI Trying to check collision");
    std::string state_name = "PepperMoveToVisualServoStart";
    (*data)["collision_parent_state"] = state_name;

    ROS_INFO("Tool Center Point pose updated to Visual Servoing Start pose.");
    usleep(100000); //0.1 s  //  1 000 000 microsecondes = 1 sec

    collisionChecked = true;
    state_transition = "CheckCollision";
    return state_transition;
  }
  // When checked on a collision, move the arm.
  else
  {
    return moveArm();
  }
}

// end effector callback function
void Pepper_MoveToVisualServoStartState::ProcessEndEffectorStatus(const crops_msgs::EndEffectorStatus::ConstPtr& msg)
{
  end_effector_status.fruit_not_removed = msg->fruit_not_removed;
  end_effector_status.gripping_failed = msg->gripping_failed;
  end_effector_status.fruit_removed = msg->fruit_removed;
  end_effector_status.cutter_ready = msg->cutter_ready;
  end_effector_status.gripping_successful = msg->gripping_successful;
  end_effector_status.gripper_ready = msg->gripper_ready;
}

/**
 * Moves arm to goal and checks on feedback.
 */
std::string Pepper_MoveToVisualServoStartState::moveArm()
{

  string outcome;
  if (first_)
  {

    ROS_INFO("#GUI moveToVisualServoStartState moveArm XPC=%i", xpc_target_);

    ROS_INFO("#GUI moveToVisualServoStartState moves to position (%.2f %.2f %.2f) ", goal_.goal_pose.position.x,
             goal_.goal_pose.position.y, goal_.goal_pose.position.z);
    ROS_INFO("#GUI moveToVisualServoStartState moves to orientation (%.2f %.2f %.2f %2f) ",
             goal_.goal_pose.orientation.x, goal_.goal_pose.orientation.y, goal_.goal_pose.orientation.z,
             goal_.goal_pose.orientation.w);

    if (n.hasParam("/robot_speed"))
    {
      ros::param::get("/robot_speed", robot_speed);
      //ROS_INFO("robot_speed=%i", robot_speed);
      if (robot_speed == 0)
        robot_speed = 1;
    }
    else
    {
      ROS_WARN("rosparam /robot_speed is not set");
      robot_speed = 100;
    }
    robot_speed_factor = 100.0 / (float)robot_speed;
    ROS_INFO("=== robot_speed=%d, robot_speed_factor=%.2f", robot_speed, robot_speed_factor);
    ROS_INFO("=== robot desired time=%.2f", 4 * robot_speed_factor);
    goal_.desired_time = 4 * robot_speed_factor; // in seconds
    //goal_.desired_time = 4; // in seconds

    goal_.use_hardware = xpc_target_;
    goal_.pathMode = 0; //added 3-4-2014 JH

    setFeedbackCallback(boost::bind(&Pepper_MoveToVisualServoStartState::feedbackCb, this, _1));
    //sleep(3);
    sendGoal();
    sleep(1);
    first_ = false;
  }

  actionlib::SimpleClientGoalState current_state_ = ac_.getState();

  switch (current_state_.state_)
  {
    /*
     * The action client (the arm) can be in different states. It's possible to define
     * what the action server (movetoFruitState) should do in each of these situations:
     case actionlib::SimpleClientGoalState::PREEMPTED:
     case actionlib::SimpleClientGoalState::RECALLED:
     case actionlib::SimpleClientGoalState::REJECTED:
     case actionlib::SimpleClientGoalState::PENDING:
     case actionlib::SimpleClientGoalState::ACTIVE:
     case actionlib::SimpleClientGoalState::LOST:
     next_state = "move to fruit";
     break;
     */
    case actionlib::SimpleClientGoalState::SUCCEEDED:
      first_ = true;
      if (ac_.getResult()->reached_goal)

      {
        ROS_INFO("#GUI Arm has reached visual servoing start position.");
        (*data_)["found_fruit"] = true;

        // Set TCP position in original position after movement
        crops_msgs::tcpInfo msg;
        msg.tcp_tooltype = 0;
        msg.tcp_tooltype = 0;
        msg.tcp_transform.translation.x = tcp_pos_[0];
        msg.tcp_transform.translation.y = tcp_pos_[1];
        msg.tcp_transform.translation.z = tcp_pos_[2];
        msg.tcp_transform.rotation.x = tcp_pos_[3];
        msg.tcp_transform.rotation.y = tcp_pos_[4];
        msg.tcp_transform.rotation.z = tcp_pos_[5];
        msg.tcp_transform.rotation.w = tcp_pos_[6];
        updateTCPsettings_.publish(msg);
        ROS_INFO("Tool Center Point pose updated to original pose.");

        // Trigger Images, wait for result and correct pose
        end_effector_command.led_status = true; // turn light on
        end_effector_control.publish(end_effector_command);
        ROS_INFO("#GUI Call correct pose start");
        correctPose();
        ROS_INFO("#GUI Call correct pose finished");
        // mini camera images are taken and processed, turn the light off
        end_effector_command.led_status = false; // turn light off
        end_effector_control.publish(end_effector_command);

        outcome = "Goal reached";
      }
      else
      {
        ROS_WARN("#GUI Not succeeded - motion not possible!!, ac_.getResult()->reached_goal==false");
        (*data_)["found_fruit"] = false;
        stat_msg_.fruit_missed = true;
        stat_msg_.start_fruit_clock = "stop";
        stat_pub_.publish(stat_msg_);
        outcome = "Out of reach";
      }
      first_ = true;
      collisionChecked = false;
      break;

    case actionlib::SimpleClientGoalState::PREEMPTED:
      ROS_INFO("#GUI Arm could not reach the fruit");
      (*data_)["found_fruit"] = false;
      first_ = true;
      collisionChecked = false;

      //bool fruit_missed # a fruit has been missed
      //bool fruit_damaged  # a fruit has been damaged
      //bool fruit_harvested  # a fruit has been harvested
      //uint32 fruit_count # No. of fruits found
      //string start_tot_clock # "start" or "stop" total time clock
      //string start_fruit_clock  # "start" or "stop" fruit time clock
      //bool reset_stats # reset all statistics and clocks to zero
      stat_msg_.fruit_missed = true;
      stat_msg_.start_fruit_clock = "stop";
      stat_pub_.publish(stat_msg_);

      outcome = "Out of reach";
      break;

    default:
      outcome = "Moving";
      break;
  }
  // TODO testing only: set collisionChecked=true always to prevent collision check
  collisionChecked = true;
  return outcome;
}

void Pepper_MoveToVisualServoStartState::correctPose()
{

  mini_cam_fruit_detected = false;

  // Trigger images
  ROS_INFO("#GUI Entered correct pose, request mini camera images");
  crops_msgs::ImageRequest img_req_msg;
  img_req_msg.num_images = 1;

  // (HOTFIX trigger 3 vrm images (but only 1 PMD) because VRM camera seems to need it after a longer pause to publish 1 image)
  // new 22-04-2014: set VRMagic in live mode, then we need to trigger only one image from VRM and PMD
  //img_req_msg.header.stamp= ros::Time::now();
  //trigger_pub_vrm_.publish(img_req_msg);
  //usleep(100000); //0.1 s  //  1000000 microsecondes = 1 sec
  //img_req_msg.header.stamp= ros::Time::now();
  //trigger_pub_vrm_.publish(img_req_msg);
  //usleep(100000); //0.1 s  //  1000000 microsecondes = 1 sec
  img_req_msg.header.stamp = ros::Time::now();
  trigger_pub_vrm_.publish(img_req_msg);
  trigger_pub_pmd_.publish(img_req_msg);
  usleep(200000); //0.2 s  //  1000000 microsecondes = 1 sec

  // Wait for publisher fruit_detected_minicam to detect a fruit or resume after timeout.
  int checks = 0;
  while ((mini_cam_fruit_detected == false) && (checks < 15)) // was 50
  {
    ROS_INFO("Waiting for fruit detection by mini camera, %i", checks);
    usleep(100000); //0.1 s  //  1000000 microsecondes = 1 sec
    checks++;
  }

  if (mini_cam_fruit_detected == true && mini_cam_fruit.FruitDetected == false)
  {
    // transformation from pmd_frame to global frame
    ROS_INFO("Fruit detection node by mini camera has returned a result but no fruit was found");
  }

  if (mini_cam_fruit_detected == true && mini_cam_fruit.FruitDetected == true)
  {
    // transformation from vrm_frame to global frame
    ROS_INFO("Fruit detection node by mini camera found a fruit");
    ROS_INFO("Minicam coordinates: (%.2f, %.2f. %.2f)", mini_cam_fruit.FruitPose.position.x,
             mini_cam_fruit.FruitPose.position.y, mini_cam_fruit.FruitPose.position.z);

    // TODO: check if fruit is found or not in the image

    geometry_msgs::PoseStamped transformed_pose;
    geometry_msgs::PoseStamped fruit_pose;

    fruit_pose.header.frame_id = mini_cam_fruit.header.frame_id;
    //fruit_pose.header.stamp = mini_cam_fruit.header.stamp;
    fruit_pose.header.stamp = ros::Time::now(); //overrule header of image!
    fruit_pose.pose = mini_cam_fruit.FruitPose;

    ROS_INFO("#GUI Detect fruit state: fruit_pose.header.frame_id=%s", fruit_pose.header.frame_id.c_str());

    try
    {
      //transformation_listener.waitForTransform(fruit_pose.header.frame_id, "/Elem_0", ros::Time(0), ros::Duration(10.0));
      //transformation_listener.transformPose("/Elem_0", ros::Time::now(), fruit_pose , fruit_pose.header.frame_id, transformed_pose);
      //TimeCacheInterfacePtr cache = getFrame(target_id);
      //dentity.header.stamp = cache->getLatestTimestamp();

      // suggestion from the internet: What usually helps is something along those lines (warning, pseudocode):
      /*time = ros::Time::now();  // or better msg->header.stamp, if available; never ros::Time(0)
       success = false;
       while (!success) {
       try {
       listener.waitForTransform(target_frame, source_frame, time, ros::Duration(3.0));
       listener.lookupTransform(target_frame, source_frame, time, st);
       success = true;
       } catch (tf::ExtrapolationException e) {
       }
       sleep(0.1);
       }
       */

      double age = ros::Time::now().toSec() - fruit_pose.header.stamp.toSec();
      ROS_INFO("Message age message timestamp mini_cam_fruit %.5f s, wait for transform:", age);

      transformation_listener.waitForTransform(fruit_pose.header.frame_id, "/Elem_0", fruit_pose.header.stamp,
                                               ros::Duration(10.0));
      transformation_listener.transformPose("/Elem_0", fruit_pose.header.stamp, fruit_pose, fruit_pose.header.frame_id,
                                            transformed_pose);
      //ROS_INFO("--------------------------------------------------------------------------");
      ROS_INFO("mini_cam_TF transform success!");

      ROS_INFO("Transforming mini cam coordinates %s: (%.2f, %.2f. %.2f) -----> Elem_0: (%.2f, %.2f, %.2f)",
               mini_cam_fruit.header.frame_id.c_str(), mini_cam_fruit.FruitPose.position.x,
               mini_cam_fruit.FruitPose.position.y, mini_cam_fruit.FruitPose.position.z,
               transformed_pose.pose.position.x, transformed_pose.pose.position.y, transformed_pose.pose.position.z);

      // Updating goal pose
      //ROS_WARN("IS DISABLED AT THIS MOMENT: Updating pose (x,y,z only) using mini camera images info.");
      ROS_INFO("Updating pose (x,y,z only) using mini camera images info.");
      goal_.goal_pose.position.x = transformed_pose.pose.position.x;
      goal_.goal_pose.position.y = transformed_pose.pose.position.y;
      goal_.goal_pose.position.z = transformed_pose.pose.position.z;
      (*data_)["arm_goal"] = goal_;
    }
    catch (tf::TransformException ex)
    {
      ROS_ERROR("mini_cam_TF transform failed!");
      ROS_ERROR("%s", ex.what());
    }

  }
  else
  {
    ROS_INFO("--------------------------------------------------------------------------");
    ROS_INFO("#GUI Fruit has not been detected in mini camera images and was not updated");
    //sleep(20);
  }

  mini_cam_fruit_detected = false;

}
